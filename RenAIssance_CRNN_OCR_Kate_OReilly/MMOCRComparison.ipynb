{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3680a16f",
   "metadata": {},
   "source": [
    "# Text Detection Comparison with MMOCR\n",
    "\n",
    "This notebook uses [MMOCR](https://github.com/open-mmlab/mmocr) to run and compare three text detectors—**CRAFT**, **DBNet**, and **PSENet**—in pure Python on Windows VSCode.\n",
    "\n",
    "Steps:\n",
    "1. Install dependencies\n",
    "2. Setup paths & imports\n",
    "3. Utility functions\n",
    "4. Initialize MMOCR detectors\n",
    "5. Inference & qualitative comparison\n",
    "6. Save side-by-side canvases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e889d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.9.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/katej/OneDrive/Documents/GitHub/RenAIssance/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 1. Install required packages (run once)\n",
    "# Uncomment and run if needed:\n",
    "# !pip install mmocr gevent-websocket munch anyconfig polygon3\n",
    "# !pip install torch torchvision torchaudio\n",
    "\n",
    "# 2. Imports & Global Paths\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from mmocr.apis import init_detector, inference_detector\n",
    "\n",
    "# Data folders\n",
    "base_dir    = os.getcwd()\n",
    "data_dir    = os.path.join(base_dir, 'data')\n",
    "image_dir   = os.path.join(data_dir, 'imgsForAllPages')\n",
    "gt_dir      = os.path.join(data_dir, 'annotations')\n",
    "output_dir  = os.path.join(base_dir, 'output')\n",
    "compare_dir = os.path.join(output_dir, 'comparisons')\n",
    "\n",
    "os.makedirs(compare_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a80ba1",
   "metadata": {},
   "source": [
    "## 3. Utility Functions\n",
    "\n",
    "Load images and ground-truth polygons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59185c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Load an image (BGR) as numpy array.\"\"\"\n",
    "    return cv2.imread(path)\n",
    "\n",
    "\n",
    "def load_ground_truth(path):\n",
    "    \"\"\"Load GT polygons from TXT (8 coords per line).\"\"\"\n",
    "    polys = []\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                coords = list(map(float, line.strip().split(',')))\n",
    "                polys.append(np.array(coords).reshape(-1,2).tolist())\n",
    "    return polys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4814c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Initialize MMOCR Detectors\n",
    "\n",
    "We point to MMOCR's config files and local checkpoints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f963df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = {\n",
    "    'CRAFT':  'mmocr/configs/textdet/craft/craft_mlt_25k.py',\n",
    "    'DBNet':  'mmocr/configs/textdet/dbnet/dbnetpp_resnet50_fpnc_1200e_icdar2015.py',\n",
    "    'PSENet': 'mmocr/configs/textdet/psenet/psenet_resnet50_fpnf_600e_ctw1500.py',\n",
    "}\n",
    "checkpoints = {\n",
    "    'CRAFT':  'CRAFTModel/weights/craft_mlt_25k.pth',\n",
    "    'DBNet':  'DB/weights/dbnetpp_resnet50_fpnc_1200e_icdar2015.pth',\n",
    "    'PSENet':'PSENet/weights/psenet_resnet50_fpnf_600e_ctw1500.pth',\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for name, cfg in configs.items():\n",
    "    print(f\"Loading {name} model…\")\n",
    "    models[name] = init_detector(cfg, checkpoints[name], device='cpu')\n",
    "print(\"All detectors loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0cc18",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Sample Inference & Visualization\n",
    "\n",
    "Run all three detectors on one example and display side-by-side.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pick first image\n",
    "img_paths = glob(os.path.join(image_dir, '*.png')) + glob(os.path.join(image_dir, '*.jpg'))\n",
    "if not img_paths:\n",
    "    raise RuntimeError(f\"No images found in {image_dir}\")\n",
    "img_path = img_paths[0]\n",
    "img = load_image(img_path)\n",
    "gt  = load_ground_truth(img_path.replace(image_dir, gt_dir).rsplit('.',1)[0] + '.txt')\n",
    "\n",
    "# collect predictions\n",
    "preds = {}\n",
    "for name, model in models.items():\n",
    "    result = inference_detector(model, img)\n",
    "    polys  = result.get('boundary_result', [])\n",
    "    preds[name] = [np.array(p).reshape(-1,2).tolist() for p in polys]\n",
    "\n",
    "# draw canvas\n",
    "y, x = img.shape[:2]\n",
    "canvas = np.zeros((y, x*4, 3), dtype=np.uint8)\n",
    "# GT\n",
    "vis = img.copy()\n",
    "for poly in gt:\n",
    "    cv2.polylines(vis, [np.array(poly, dtype=np.int32).reshape(-1,1,2)], True, (0,255,0), 2)\n",
    "canvas[:, :x] = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "# each model\n",
    "for i,(name, boxes) in enumerate(preds.items(), start=1):\n",
    "    vis = img.copy()\n",
    "    for poly in boxes:\n",
    "        cv2.polylines(vis, [np.array(poly, dtype=np.int32).reshape(-1,1,2)], True, (255,0,0), 2)\n",
    "    canvas[:, i*x:(i+1)*x] = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(canvas)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e735b",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Batch Inference & Save Comparisons\n",
    "\n",
    "Loop through all images and save side-by-side comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img_path in img_paths:\n",
    "    img = load_image(img_path)\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    gt   = load_ground_truth(img_path.replace(image_dir, gt_dir).rsplit('.',1)[0] + '.txt')\n",
    "\n",
    "    # predictions\n",
    "    preds = {}\n",
    "    for name, model in models.items():\n",
    "        res   = inference_detector(model, img)\n",
    "        polys = res.get('boundary_result', [])\n",
    "        preds[name] = [np.array(p).reshape(-1,2).tolist() for p in polys]\n",
    "\n",
    "    # build canvas\n",
    "    h,w = img.shape[:2]\n",
    "    canvas = np.zeros((h, w*4, 3), dtype=np.uint8)\n",
    "    # GT\n",
    "    vis_gt = img.copy()\n",
    "    for poly in gt:\n",
    "        cv2.polylines(vis_gt, [np.array(poly, dtype=np.int32).reshape(-1,1,2)], True, (0,255,0), 2)\n",
    "    canvas[:, :w] = cv2.cvtColor(vis_gt, cv2.COLOR_BGR2RGB)\n",
    "    # models\n",
    "    for i,(name,boxes) in enumerate(preds.items(), start=1):\n",
    "        vis = img.copy()\n",
    "        for poly in boxes:\n",
    "            cv2.polylines(vis, [np.array(poly, dtype=np.int32).reshape(-1,1,2)], True, (255,0,0), 2)\n",
    "        canvas[:, i*w:(i+1)*w] = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    save_path = os.path.join(compare_dir, f\"{base}_compare.png\")\n",
    "    Image.fromarray(canvas).save(save_path)\n",
    "    print(f\"Saved comparison: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
